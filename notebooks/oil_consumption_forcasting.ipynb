{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams['font.size'] = 12\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data\n",
    "Data is preprocessed in the [data preprocessing](./create_dataset.ipynb) notebook. This includes concatenating the data, removing outliers, missing values, and irrelevant columns and generating relevant features based on given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_day = pd.read_pickle('../data/processed/data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_day.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns from object to datetime\n",
    "date_cols = ['Zeitstempel', 'Sicherheitsbestand wird erreicht am', 'Meldebestand wird erreicht am']\n",
    "for col in date_cols:\n",
    "    data_per_day[col] = pd.to_datetime(data_per_day[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build target variable \"Verbrauch\" per day\n",
    "Difference of the \"Füllstand\" the current day to the next day. This is the oil consumption per day. Implementation also see [data preprocessing](./create_dataset.ipynb), calculate \"Füllstand\" difference from day before to current day, then shift by one day to the past, since this difference is the consumption of the day before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat matching historical weather data\n",
    "We implemented a wrapper to gain historical and forecast weather data per day using an open source API, see in [weather data](../src/api/weather.py) notebook. This then can be easily concatenated as an external feature to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_day.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.api import WeatherAPI\n",
    "\n",
    "weather_api = WeatherAPI()\n",
    "\n",
    "for id in data_per_day[\"Tank-ID\"].unique():\n",
    "    # get attributes\n",
    "    latitude = data_per_day[data_per_day[\"Tank-ID\"] == id][\"Längengrad\"].iloc[0]\n",
    "    longitude = data_per_day[data_per_day[\"Tank-ID\"] == id][\"Breitengrad\"].iloc[0]\n",
    "    if data_per_day[\"Zeitstempel\"].dtypes == 'object':\n",
    "        data_per_day[\"Zeitstempel\"] = pd.to_datetime(data_per_day[\"Zeitstempel\"])\n",
    "    start_date = data_per_day[\"Zeitstempel\"].min().strftime(\"%Y-%m-%d\")\n",
    "    end_date = data_per_day[\"Zeitstempel\"].max().strftime(\"%Y-%m-%d\")\n",
    "    print(\"Start date:\", start_date, \"End date:\", end_date)\n",
    "\n",
    "\n",
    "    # get matching weather data\n",
    "    weather_data = weather_api.get_data(latitude, longitude, start_date, end_date)\n",
    "\n",
    "    # remove timezone information\n",
    "    weather_data['date'] = weather_data['date'].dt.tz_localize(None)\n",
    "\n",
    "    # join data\n",
    "    print(\"Weather data for tank ID\", id, \"shape:\", weather_data.shape)\n",
    "    print(\"Data per day for tank ID\", id, \"shape:\", data_per_day[data_per_day[\"Tank-ID\"] == id].shape)\n",
    "    data_per_day = data_per_day.merge(weather_data, left_on='Zeitstempel', right_on='date', how='left')\n",
    "    print(\"Merged data shape:\", data_per_day.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train and Test Data\n",
    "For forcasting following steps are necessary:\n",
    "1. Split data into train and test data\n",
    "2. Normalize data\n",
    "3. (Create sequences of data)\n",
    "5. Split data into X and y\n",
    "8. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "cols_to_drop = [\"Sicherheitsbestand wird erreicht am\", \"Meldebestand wird erreicht am\"] # \"Füllstand\"\n",
    "df = data_per_day.drop(cols_to_drop, axis=1)\n",
    "# drop ID 5 - remove later on, since it is included in the data cleaning process\n",
    "df = df[df['Tank-ID'] != 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to \"Zeitstempel\"\n",
    "df = df.set_index('Zeitstempel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot time series based on tank ID\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for tank_id in df[\"Tank-ID\"].unique():\n",
    "    df[df[\"Tank-ID\"] == tank_id][\"Füllstand\"].plot(ax=ax, label=f'Tank {tank_id}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Füllstand')\n",
    "plt.title('\"Füllstand\" over time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test data, based on tank ID\n",
    "train_data = df[df['Tank-ID'] != 2]\n",
    "test_data = df[df['Tank-ID'] == 2]\n",
    "\n",
    "# get x and y values\n",
    "X_train = train_data.drop('Verbrauch', axis=1).values\n",
    "y_train = train_data['Verbrauch'].values\n",
    "X_test = test_data.drop('Verbrauch', axis=1).values\n",
    "y_test = test_data['Verbrauch'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "* via correlation\n",
    "* via feature importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: ARIMA model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Prophet model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Simple ML model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
